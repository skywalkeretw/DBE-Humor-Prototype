{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-05 16:13:32--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
      "Resolving download.microsoft.com (download.microsoft.com)... 2.18.232.239, 2a02:26f0:6c00:29b::317f, 2a02:26f0:6c00:2a9::317f\n",
      "Connecting to download.microsoft.com (download.microsoft.com)|2.18.232.239|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 824887076 (787M) [application/octet-stream]\n",
      "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
      "\n",
      "/tmp/cats-and-dogs. 100%[===================>] 786.67M  34.0MB/s    in 22s     \n",
      "\n",
      "2022-11-05 16:13:54 (36.5 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824887076/824887076]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!curl -L \"https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\" -o \"/tmp/cats-and-dogs.zip\"\n",
    "!wget --no-check-certificate \\\n",
    "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" \\\n",
    "    -O '/tmp/cats-and-dogs.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/tmp/cats-and-dogs/'\n",
    "\n",
    "local_zip = \"/tmp/cats-and-dogs.zip\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(base_dir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Pictures: 12501\n",
      "Dog Pictures: 12501\n"
     ]
    }
   ],
   "source": [
    "print(\"Cat Pictures: \" + str(len(os.listdir(base_dir + 'PetImages/Cat/'))))\n",
    "print(\"Dog Pictures: \" + str(len(os.listdir(base_dir + 'PetImages/Dog/'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(base_dir + 'training')\n",
    "    os.mkdir(base_dir + 'training/cats')\n",
    "    os.mkdir(base_dir + 'training/dogs')\n",
    "    \n",
    "    os.mkdir(base_dir + 'testing')\n",
    "    os.mkdir(base_dir + 'testing/cats')\n",
    "    os.mkdir(base_dir + 'testing/dogs')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_pics(SOURCE_FOLDER, DESTINATION_FOLDER, SET):\n",
    "    for filename in SET:\n",
    "        this_file = SOURCE_FOLDER + filename\n",
    "        destination = DESTINATION_FOLDER + filename\n",
    "        copyfile(this_file, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is Zero length, so ignoring.\")\n",
    "    \n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    \n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    \n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "    \n",
    "    copy_pics(SOURCE, TRAINING, training_set)\n",
    "    copy_pics(SOURCE, TESTING, testing_set)\n",
    "    \n",
    "    print(\"SOURCE: \" + SOURCE + \" len:\" + str(len(os.listdir(SOURCE))))\n",
    "    print(\"TRAINING: \" + TRAINING + \" len:\" + str(len(os.listdir(TRAINING))))\n",
    "    print(\"TESTING: \" + TESTING + \" len:\" + str(len(os.listdir(TESTING))))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_SOURCE_DIR = base_dir + 'PetImages/Cat/'\n",
    "TRAINING_CATS_DIR = base_dir + 'training/cats/'\n",
    "TESTING_CATS_DIR = base_dir + 'testing/cats/'\n",
    "\n",
    "DOG_SOURCE_DIR = base_dir + 'PetImages/Dog/'\n",
    "TRAINING_DOGS_DIR = base_dir + 'training/dogs/'\n",
    "TESTING_DOGS_DIR = base_dir + 'testing/dogs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666.jpg is Zero length, so ignoring.\n",
      "SOURCE: /tmp/cats-and-dogs/PetImages/Cat/ len:12501\n",
      "TRAINING: /tmp/cats-and-dogs/training/cats/ len:12500\n",
      "TESTING: /tmp/cats-and-dogs/testing/cats/ len:3391\n",
      "11702.jpg is Zero length, so ignoring.\n",
      "SOURCE: /tmp/cats-and-dogs/PetImages/Dog/ len:12501\n",
      "TRAINING: /tmp/cats-and-dogs/training/dogs/ len:12500\n",
      "TESTING: /tmp/cats-and-dogs/testing/dogs/ len:3382\n"
     ]
    }
   ],
   "source": [
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(learning_rate=0.001),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24998 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = base_dir + 'training/'\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    batch_size=250,\n",
    "    class_mode='binary',\n",
    "    target_size=(150, 150)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6773 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_DIR = base_dir + 'testing/'\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    batch_size=250,\n",
    "    class_mode='binary',\n",
    "    target_size=(150, 150)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "89/90 [============================>.] - ETA: 2s - loss: 0.7143 - accuracy: 0.5681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:850: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 220s 2s/step - loss: 0.7133 - accuracy: 0.5690 - val_loss: 0.6321 - val_accuracy: 0.6392\n",
      "Epoch 2/15\n",
      "90/90 [==============================] - 217s 2s/step - loss: 0.6008 - accuracy: 0.6751 - val_loss: 0.5723 - val_accuracy: 0.6912\n",
      "Epoch 3/15\n",
      "90/90 [==============================] - 217s 2s/step - loss: 0.5384 - accuracy: 0.7265 - val_loss: 0.5056 - val_accuracy: 0.7632\n",
      "Epoch 4/15\n",
      "90/90 [==============================] - 216s 2s/step - loss: 0.4993 - accuracy: 0.7518 - val_loss: 0.5457 - val_accuracy: 0.7188\n",
      "Epoch 5/15\n",
      "90/90 [==============================] - 217s 2s/step - loss: 0.4688 - accuracy: 0.7761 - val_loss: 0.4395 - val_accuracy: 0.8008\n",
      "Epoch 6/15\n",
      "90/90 [==============================] - 218s 2s/step - loss: 0.4498 - accuracy: 0.7860 - val_loss: 0.3998 - val_accuracy: 0.8248\n",
      "Epoch 7/15\n",
      "90/90 [==============================] - 216s 2s/step - loss: 0.4130 - accuracy: 0.8110 - val_loss: 0.3362 - val_accuracy: 0.8620\n",
      "Epoch 8/15\n",
      "90/90 [==============================] - 217s 2s/step - loss: 0.3938 - accuracy: 0.8179 - val_loss: 0.3545 - val_accuracy: 0.8536\n",
      "Epoch 9/15\n",
      "90/90 [==============================] - 218s 2s/step - loss: 0.3698 - accuracy: 0.8341 - val_loss: 0.3451 - val_accuracy: 0.8428\n",
      "Epoch 10/15\n",
      "90/90 [==============================] - 216s 2s/step - loss: 0.3411 - accuracy: 0.8465 - val_loss: 0.3570 - val_accuracy: 0.8264\n",
      "Epoch 11/15\n",
      "90/90 [==============================] - 216s 2s/step - loss: 0.3141 - accuracy: 0.8652 - val_loss: 0.2412 - val_accuracy: 0.8992\n",
      "Epoch 12/15\n",
      "90/90 [==============================] - 216s 2s/step - loss: 0.2822 - accuracy: 0.8807 - val_loss: 0.2638 - val_accuracy: 0.8896\n",
      "Epoch 13/15\n",
      "90/90 [==============================] - 215s 2s/step - loss: 0.2484 - accuracy: 0.8989 - val_loss: 0.5207 - val_accuracy: 0.7488\n",
      "Epoch 14/15\n",
      "90/90 [==============================] - 215s 2s/step - loss: 0.2138 - accuracy: 0.9157 - val_loss: 0.1250 - val_accuracy: 0.9612\n",
      "Epoch 15/15\n",
      "90/90 [==============================] - 216s 2s/step - loss: 0.1744 - accuracy: 0.9337 - val_loss: 0.0789 - val_accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=15, \n",
    "    steps_per_epoch=90, \n",
    "    validation_data=validation_generator, \n",
    "    validation_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpimg\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google colab test using upload\n",
    "import numpyy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn inuploadedoadedploaded.keys():\n",
    "    path = '/content/' + fn\n",
    "    img = image.load_img(path, target_size(150, 15imagege\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(fn + \" is a dog\")\n",
    "    else:\n",
    "        print(fn + \" is a cat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
